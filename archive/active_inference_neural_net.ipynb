{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "active_inference_neural_net.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "e134e05457d34029b6460cd73bbf1ed73f339b5b6d98c95be70b69eba114fe95"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def softmax(X):                                                                 ###converts log probabilities to probabilities\n",
        "  norm = np.sum(np.exp(X)+10**-5)\n",
        "  Y = (np.exp(X)+10**-5)/norm\n",
        "  return Y\n",
        "\n",
        "def softmax_dim2(X):                                                            ###converts matrix of log probabilities to matrix of probabilities\n",
        "  norm = np.sum(np.exp(X)+10**-5,axis=0)\n",
        "  Y = (np.exp(X)+10**-5)/norm\n",
        "  return Y\n",
        "\n",
        "def normalise(X):                                                               ###normalises a matrix of probabilities\n",
        "  X= X/np.sum(X,0)\n",
        "  return X\n",
        "\n",
        "def predict(X,B):\n",
        "  return np.inner(B,X)                                                          # Generate next state estimate, prediction step of filter\n",
        "\n",
        "# Correction step given a likelihood matrix and observation vector.\n",
        "# Formally a backwards BP message over a discrete transition node.\n",
        "# Observations are np arrays that sum to 1, ie Categorical distributions\n",
        "def obs_correct(X,A,obs):\n",
        "  return softmax(np.log(X)+np.log(np.transpose(A) @ obs))\n",
        "  \n",
        "# Check if we pass a confidence threshold for network activity\n",
        "def fire(X,threshold):\n",
        "    return X > threshold"
      ],
      "outputs": [],
      "metadata": {
        "id": "Q6xi1vBJaAHg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "source": [
        "# parameter functions\n",
        "\n",
        "# Likelihood matrix defined for each presynaptic neuron with some initial confidence (Palacios et al. use 0.5) on observations. \n",
        "\n",
        "def get_likelihood(number_of_presynaptic_neurons, initial_confidence):\n",
        "  ''' \n",
        "  Generates the likelihood matrices given the number of inputs and initial observation precision. \n",
        "  '''\n",
        "  p = initial_confidence\n",
        "  assert 0 <= p <= 1, \"Confidence must be in range [0,1]\"\n",
        "  A = np.zeros((number_of_presynaptic_neurons,2,2))\n",
        "  for i in range(number_of_presynaptic_neurons):\n",
        "    A[i,:,0] = [1-p , p]\n",
        "    A[i,:,1] = [p , 1-p]\n",
        "  return A\n",
        "\n",
        "# Inspired by Palacios et al. 2019\n",
        "# Tranisition matrix depends on the neuron's 'memory' of it's own recent activity. \n",
        "# If the neuron has fired in the 'interspike interval' then it expects to continue firing. \n",
        "# This slightly unusual formulation approximates a deep temporal model. \n",
        "\n",
        "def get_transition_matrix(tau, t_min, t_max, Xbar):\n",
        "  recent_fire = 0\n",
        "  B = np.zeros((2,2))\n",
        "\n",
        "  for x in Xbar[0,max(0,tau-t_max):max(0,tau-t_min)]:\n",
        "    if x > 0.5: \n",
        "      recent_fire = 1\n",
        "      break\n",
        "  if recent_fire == 0:\n",
        "    B[:,0]=[0.2,.8]\n",
        "    B[:,1]=[0.2,.8]\n",
        "  else:\n",
        "    B[:,0]=[.8,.2]\n",
        "    B[:,1]=[.8,.2]  \n",
        "  return B\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "us7hZRektWK_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "source": [
        "# parameters for testing\n",
        "number_of_presynaptic_neurons = 1\n",
        "\n",
        "#timesteps\n",
        "T = 20\n",
        "\n",
        "# initial time step\n",
        "tau = 0\n",
        "\n",
        "# interspike interval\n",
        "t_min = 1\n",
        "t_max = 3\n",
        "\n",
        "# initialise internal neuron state priors and posteriors (network firing vs network silent)\n",
        "X = np.zeros((2,T))\n",
        "Xbar = np.zeros((2,T))\n",
        "\n",
        "# state prior D\n",
        "X[:,0] = [0.5,0.5]\n",
        "\n",
        "# observations (silent 0 vs fire 1)\n",
        "O = np.zeros(T)\n",
        "\n",
        "# initial input\n",
        "\n",
        "O = np.ones(T)\n",
        "O[6] = 0\n",
        "O[7] = 0\n",
        "O[8] = 0\n",
        "O[9] = 0\n",
        "O[10] = 0\n",
        "O[11] = 0\n",
        "\n",
        "# action potential generated by the neuron (starts silent)\n",
        "O_out = np.zeros(T-1)\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# run experiment for one neuron\n",
        "\n",
        "A = get_likelihood(1, 0.95)\n",
        "\n",
        "for t in range(T):\n",
        "    print(t)\n",
        "    # get internal model based on historic activity\n",
        "    B_t = get_transition_matrix(t, t_min, t_max, Xbar)\n",
        "\n",
        "    ## calculate perceptual state posterior given observation\n",
        "    Xbar[:,t] = softmax(np.log(X[:,t])+np.log(A[0,int(O[t]),:]))\n",
        "\n",
        "    if t < (T-1):\n",
        "        # generate action - the probability of firing depends on the neuron's beleif that it is participating in a firing vs silent network\n",
        "        O_out[t] = np.random.choice([1,0], p=Xbar[:,t])\n",
        "\n",
        "        #evolve expected state\n",
        "        X[:,t+1] = np.inner(B_t, Xbar[:,t])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "source": [
        "# define connections between neurons (1 if connected)\n",
        "connectivity_matrix = np.array([[0,1],[0,0]])\n",
        "unique, counts = np.unique(connectivity_matrix[0], return_counts=True)\n",
        "print(counts)\n",
        "\n",
        "output_matrix = np.zeros((len(connectivity_matrix),T))\n",
        "print(output_matrix)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "source": [
        "class Neuron:\n",
        "    def __init__(self, index, connectivity_matrix, output_matrix, T):\n",
        "        self.index = index\n",
        "        self.init_precision = 0.9\n",
        "        u, counts = np.unique(connectivity_matrix[self.index], return_counts=True)\n",
        "        assert len(counts) == 2, \"Neuron has no connections. Check the connectivity matrix.\"\n",
        "        self.number_of_presynaptic_neurons = counts[1]\n",
        "        self.A = get_likelihood(self.number_of_presynaptic_neurons, self.init_precision)\n",
        "        self.X = np.zeros((2,T))\n",
        "        self.X[:,0] = [0.5,0.5]\n",
        "        self.Xbar = np.zeros((2,T))\n",
        "        self.O = np.zeros(T)\n",
        "        self.O_out = output_matrix[0]\n",
        "\n",
        "        # define 'refractory period'\n",
        "        self.t_min = 1\n",
        "        self.t_max = 3\n",
        "\n",
        "    def get_transition_matrix(self, t):\n",
        "        recent_fire = 0\n",
        "        B = np.zeros((2,2))\n",
        "        for x in self.Xbar[0,max(0,t-self.t_max):max(0,t-self.t_min)]:\n",
        "            if x > 0.5: \n",
        "                recent_fire = 1\n",
        "                break\n",
        "        if recent_fire == 0:\n",
        "            B[:,0]=[0.2,.8]\n",
        "            B[:,1]=[0.2,.8]\n",
        "        else:\n",
        "            B[:,0]=[.8,.2]\n",
        "            B[:,1]=[.8,.2]  \n",
        "        return B\n",
        "\n",
        "    def perceive_network(self, t):\n",
        "        self.O[t] = output_matrix[1,t]\n",
        "        self.Xbar[:,t] = softmax(np.log(self.X[:,t])+np.log(self.A[0,int(self.O[t]),:]))\n",
        "        return self.Xbar[:,t]\n",
        "\n",
        "    def broadcast_beliefs(self, t):\n",
        "        self.O_out[t] = np.random.choice([1,0], p=self.Xbar[:,t])\n",
        "        return self.O_out[t]\n",
        "\n",
        "    def predict(self, t):\n",
        "        B_t = get_transition_matrix(t)\n",
        "        self.X[:,t+1] = np.inner(B_t, self.Xbar[:,t])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "source": [
        "neuron_0 = Neuron(0, connectivity_matrix, 0.9, T)\n",
        "print(neuron_0.number_of_presynaptic_neurons)\n",
        "neuron_0.A"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.1, 0.9],\n",
              "        [0.9, 0.1]]])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "\n",
        "#plt.plot(1.5+np.arange(0,T-1),Pi2[0,:-1],label='stay (prior)',linestyle='--')\n",
        "#plt.plot(np.arange(1,T),Pi2[1,:-1],label='switch (prior')\n",
        "plt.plot(np.arange(0,T),Xbar[0,:],label=r'${\\bar{X}}}$',color='coral')\n",
        "plt.scatter(np.arange(T),O,label='inputs',color='orangered')\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.ylim([0,1.0])\n",
        "plt.yticks([-0.05,1.05],['silent','firing'])\n",
        "#plt.ylabel(r'$\\pi^{(2)}$')\n",
        "plt.title('Neural posterior beliefs of network state')\n",
        "plt.xlim([0,T])\n",
        "\n",
        "plt.tight_layout()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "print(A[0,0,:])\n",
        "print(A[0,1,:])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 0.]\n",
            "[0. 1.]\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "print(O)\n",
        "\n",
        "print(X)\n",
        "print(Xbar)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
            "[[0.5 0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
            " [0.5 0.  1.  1.  1.  1.  1.  1.  1.  1. ]]\n",
            "[[1.00015999e-01 5.00000000e-01 1.11108642e-05 9.99800040e-05\n",
            "  1.11108642e-05 9.99800040e-05 1.11108642e-05 9.99800040e-05\n",
            "  1.11108642e-05 9.99800040e-05]\n",
            " [8.99984001e-01 5.00000000e-01 9.99988889e-01 9.99900020e-01\n",
            "  9.99988889e-01 9.99900020e-01 9.99988889e-01 9.99900020e-01\n",
            "  9.99988889e-01 9.99900020e-01]]\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code below from doubletake as reference"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_params(p1, p2):\n",
        "    ### Defining A matrices for multi-modal, precision modulated observations\n",
        "    A1 = [[p1, 1-p1], [1-p1, p1]]\n",
        "    A2 = [[p2, 1-p2], [1-p2, p2]]\n",
        "\n",
        "    # Higher level likelihood. We can weigh audio/video differently here\n",
        "    A3 = np.eye(2)\n",
        "\n",
        "    # TO DO: think about what makes sense here.\n",
        "    # We can flex this to get the right 'windowing',\n",
        "    # ie. a suitable decay rate of beliefs will allow audio and video\n",
        "    # outputs to build on eachother even if they arrive in different time-windows.\n",
        "\n",
        "    # Audio\n",
        "    B1 = np.zeros((2,2))\n",
        "    B1[:,0]=[0.8,0.2]\n",
        "    B1[:,1]=[0.2,0.8]\n",
        "\n",
        "    # Video\n",
        "    B2 = np.zeros((2,2))\n",
        "    B2[:,0]=[0.915,0.085]\n",
        "    B2[:,1]=[0.085,0.915]\n",
        "\n",
        "    # Higher\n",
        "    B3 = np.zeros((2,2))\n",
        "    B3[:,0]=[0.81,0.19]\n",
        "    B3[:,1]=[0.19,0.81]\n",
        "\n",
        "    return A1,A2,A3,B1, B2, B3"
      ],
      "outputs": [],
      "metadata": {
        "id": "LtHQvCtZaEPY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def run_experiment(video_clap, audio_clap, no_hands, distance):\n",
        "    # belief threshold that marks the moment a clap is perceived\n",
        "    threshold = 0.8\n",
        "\n",
        "    # Number of time steps\n",
        "    T = 100\n",
        "    timestep = 0\n",
        "\n",
        "    # Get parameters for Lars' original simulation,works with T=100\n",
        "    # Eventually, take out precision as well and replace with live inputs,\n",
        "    # this means that T will no longer be needed\n",
        "    # T will become p1 and p2 for audio and video and be moved into the while loop\n",
        "    _,_,A3,B1,B2,B3 = get_params(0, 0)\n",
        "\n",
        "    # initial state,2nd layer\n",
        "    X_2_min = [0.5, 0.5]\n",
        "    # initial state, audio\n",
        "    X_audio_min = [0.5, 0.5]\n",
        "    # initial state, video\n",
        "    X_video_min = [0.5, 0.5]\n",
        "\n",
        "    claps = []\n",
        "    clap_prev = False\n",
        "\n",
        "    # State Check Variables\n",
        "    ignore_state = False\n",
        "    state, step1, step2, memory, O_video_old, p2_old = 0, 0, 0, 0, 0, 0\n",
        "\n",
        "    # perception posterior (no clap vs clap)\n",
        "    X_output = []\n",
        "    # Xbar = np.append(np.array([[0.5, 0.5]]), np.zeros((1,2)), axis=0) # 0.5 0.5 would be the x_t in this case\n",
        "    X_t_audio_min = X_audio_min\n",
        "    X_t_video_min = X_video_min\n",
        "    X_t_2_min = X_2_min\n",
        "\n",
        "    # Number of iterations at hands are not in frame\n",
        "    num_not_visible = 0\n",
        "    no_hands_detected = True\n",
        "\n",
        "    # Establish the socket connection to Unity app\n",
        "    manager = ConnectionManager()\n",
        "    connection_to_server = Connection(\"server\", '127.0.0.1', 8055, ConnectionType.CLIENT)\n",
        "    manager.add_connection(connection_to_server)\n",
        "\n",
        "    while 1:\n",
        "\n",
        "        # Calls the video and audio inputs and returns the observation and confidence values\n",
        "        O_video, p2, vel, O_audio, p1, video_flag, audio_flag = receive_inputs(video_clap, audio_clap)\n",
        "\n",
        "        # Checks whether inputs are connected\n",
        "        # ignore_state, O_video, p2, step1, step2 = check_state(timestep, O_video, p2, video_flag, audio_flag, ignore_state, state, step1, step2, memory, O_video_old, p2_old, no_hands)\n",
        "        \n",
        "        # This checks if hands are present in the frame of the camera and returns a distance values for the hands\n",
        "        try:\n",
        "            no_hands_detected = no_hands.get_nowait()\n",
        "            print(no_hands_detected)\n",
        "        except:\n",
        "            no_hands_detected = False\n",
        "\n",
        "        if no_hands_detected is False:\n",
        "            try:\n",
        "                distance_hands = distance.get_nowait()\n",
        "                # then send the distance\n",
        "                print('sending distance to unity')\n",
        "            except:\n",
        "                distance_hands = -1\n",
        "      \n",
        "\n",
        "        # Checks if audio and/or video were detected in the same frame\n",
        "        if audio_flag == True or video_flag == True:\n",
        "            # print(\"CLAP\")\n",
        "            A1,A2,A3,B1,B2,B3 = get_params(p1, p2)\n",
        "\n",
        "        # Prediction for next time step. This gives us p(x_t | x_{t-1})\n",
        "        # 3 states: Audio, video, higher layer\n",
        "        # Currently just 1 transition matrix. Each state needs its own B\n",
        "        X_t_audio = predict(X_t_audio_min,B1)\n",
        "        X_t_video = predict(X_t_video_min,B2)\n",
        "        X_t_2 = predict(X_t_2_min,B3)\n",
        "\n",
        "        # If we have observations, do a correction step\n",
        "        # Can we make the output a [0,1] vector in case of clap? Then we can use a generic correction function\n",
        "        if audio_flag == True:\n",
        "            # Select the observation - this is a bit unusual\n",
        "            X_t_audio = correct_proper(X_t_audio,A1,[1-O_audio, O_audio])\n",
        "        if video_flag == True:\n",
        "            X_t_video = correct_proper(X_t_video,A2,[1-O_video, O_video])\n",
        "\n",
        "        # Update higher layer. We always incorporate information from lower layers since it's always available\n",
        "        # Note that we use a different correction step since we don't have obs in the form of an A-matrix as in Lars' original model\n",
        "        q_X_t_2 = correct_proper(X_t_2,A3,X_t_audio)\n",
        "        q_X_t_2 = correct_proper(q_X_t_2,A3,X_t_video)\n",
        "\n",
        "        # Store the output\n",
        "        X_output.append(q_X_t_2[1])\n",
        "\n",
        "        # Do we detect a clap? Check second dimension of hidden state\n",
        "        clap = clap_detected(q_X_t_2[1],threshold)\n",
        "\n",
        "        # Peak Detection\n",
        "        clap, clap_prev = peak_detection(clap, clap_prev)\n",
        "        \n",
        "        ## Sync Check that is linked with the check_state() function above\n",
        "        ## May be useful later, keep just in case for now\n",
        "        # try:\n",
        "        #     if ignore_state == True and claps[step1] == True:\n",
        "        #         clap = False\n",
        "        #         ignore_state = False\n",
        "        # except IndexError:\n",
        "        #     pass\n",
        "\n",
        "        # Check if True and send to Unity App\n",
        "        if clap == True: \n",
        "            manager.enqueue_message((connection_to_server, (Message(Body([1, int(vel*100), int(distance_hands*100), 2, 5])))))  \n",
        "\n",
        "        # Add results to the clap list\n",
        "        claps.append(clap)\n",
        "\n",
        "\n",
        "        # Reset for the next iteration\n",
        "        X_t_audio_min = X_t_audio\n",
        "        X_t_video_min = X_t_video\n",
        "        X_t_2_min = q_X_t_2\n",
        "\n",
        "        timestep +=1\n",
        "\n",
        "        # Calls the function to output a plot of the clap signals\n",
        "        # plot_output(timestep, T, claps, X_output, threshold)"
      ],
      "outputs": [],
      "metadata": {
        "id": "aPCvBKxuboHL"
      }
    }
  ]
}